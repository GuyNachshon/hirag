# Whisper Service using Ivrit-AI models with FastAPI endpoints
FROM pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime

WORKDIR /app

# Configure LD_LIBRARY_PATH (from Ivrit-AI setup)
ENV LD_LIBRARY_PATH="/opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib:/opt/conda/lib/python3.11/site-packages/nvidia/cublas/lib"

# Install system dependencies
RUN apt update && apt install -y \
    ffmpeg \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages (based on Ivrit-AI requirements)
RUN pip install --no-cache-dir \
    ivrit==0.1.2 \
    fastapi==0.104.1 \
    uvicorn==0.24.0 \
    python-multipart \
    librosa \
    numpy \
    requests

# Environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface
ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1
ENV DEVICE=cuda
ENV MODEL_NAME=ivrit-ai/whisper-large-v3-ct2

# Pre-download models (based on Ivrit-AI Dockerfile)
RUN python3 -c 'import faster_whisper; m = faster_whisper.WhisperModel("ivrit-ai/whisper-large-v3-turbo-ct2")'
RUN python3 -c 'import faster_whisper; m = faster_whisper.WhisperModel("ivrit-ai/whisper-large-v3-ct2")'
RUN python3 -c 'import pyannote.audio; p = pyannote.audio.Pipeline.from_pretrained("ivrit-ai/pyannote-speaker-diarization-3.1")'
RUN python3 -c 'from speechbrain.inference.speaker import EncoderClassifier; EncoderClassifier.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")'

# Copy the Whisper FastAPI service
COPY source-code/whisper_fastapi_service.py ./whisper_fastapi_service.py

# Create startup script
RUN cat > start_whisper_service.sh << 'EOF'
#!/bin/bash
echo "Starting Ivrit-AI Whisper FastAPI Service"
echo "Model: $MODEL_NAME"
echo "Device: $DEVICE"
echo "Offline Mode: $HF_HUB_OFFLINE"

# Ensure GPU is accessible
if [ "$DEVICE" = "cuda" ]; then
    python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"
fi

# Start service
exec python whisper_fastapi_service.py
EOF

RUN chmod +x start_whisper_service.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8004/health || exit 1

EXPOSE 8004

CMD ["./start_whisper_service.sh"]