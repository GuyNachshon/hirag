# Whisper Service using Ivrit-AI models with FastAPI endpoints
FROM pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime

WORKDIR /app

# Configure LD_LIBRARY_PATH (from Ivrit-AI setup)
ENV LD_LIBRARY_PATH="/opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib:/opt/conda/lib/python3.11/site-packages/nvidia/cublas/lib"

# Install system dependencies
RUN apt update && apt install -y \
    ffmpeg \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages (based on Ivrit-AI requirements)
RUN pip install --no-cache-dir \
    ivrit==0.1.2 \
    fastapi==0.104.1 \
    uvicorn==0.24.0 \
    python-multipart \
    librosa \
    numpy \
    requests

# Environment variables (offline mode disabled for downloads)
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface
ENV DEVICE=cuda
ENV MODEL_NAME=ivrit-ai/whisper-large-v3-ct2

# Pre-download models (with internet access)
RUN python3 -c 'import faster_whisper; m = faster_whisper.WhisperModel("ivrit-ai/whisper-large-v3-turbo-ct2")'
RUN python3 -c 'import faster_whisper; m = faster_whisper.WhisperModel("ivrit-ai/whisper-large-v3-ct2")'
RUN python3 -c 'import pyannote.audio; p = pyannote.audio.Pipeline.from_pretrained("ivrit-ai/pyannote-speaker-diarization-3.1")'
RUN python3 -c 'from speechbrain.inference.speaker import EncoderClassifier; EncoderClassifier.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")'

# Enable offline mode after downloads
ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1

# Copy the Whisper FastAPI service and startup script
COPY source-code/whisper_fastapi_service.py ./whisper_fastapi_service.py
COPY source-code/start_whisper_service.sh ./start_whisper_service.sh

# Make startup script executable
RUN chmod +x start_whisper_service.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8004/health || exit 1

EXPOSE 8004

CMD ["./start_whisper_service.sh"]