# DotsOCR Vision Server Dockerfile
FROM rednotehilab/dots.ocr:latest

# Set working directory
WORKDIR /app

# Download and embed DotsOCR model directly in the image
RUN mkdir -p /app/weights/DotsOCR && \
    python3 -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='rednote-hilab/dots.ocr',
    local_dir='/app/weights/DotsOCR',
    local_dir_use_symlinks=False
)
print('DotsOCR model embedded in image')
"

# Set environment variables
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTHONPATH="/app/weights/DotsOCR:$PYTHONPATH"

# Expose port
EXPOSE 8000

# Create startup script
RUN echo '#!/bin/bash\n\
export hf_model_path=./weights/DotsOCR\n\
export PYTHONPATH=$(dirname "$hf_model_path"):$PYTHONPATH\n\
sed -i "/^from vllm\.entrypoints\.cli\.main import main$/a\\from DotsOCR import modeling_dots_ocr_vllm" $(which vllm)\n\
vllm serve $hf_model_path \\\n\
  --tensor-parallel-size 1 \\\n\
  --gpu-memory-utilization 0.95 \\\n\
  --chat-template-content-format string \\\n\
  --served-model-name model \\\n\
  --trust-remote-code \\\n\
  --host 0.0.0.0 \\\n\
  --port 8000' > /app/start_dots_ocr.sh

RUN chmod +x /app/start_dots_ocr.sh

CMD ["/app/start_dots_ocr.sh"]